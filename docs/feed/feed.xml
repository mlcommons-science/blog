<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:base="en">
	<title>MLCommons Science</title>
	<subtitle>The MLCommons Science Blog.</subtitle>
	<link href="https://mlcommons-science.netlify.app/feed/feed.xml" rel="self"/>
	<link href="https://mlcommons-science.netlify.app/"/>
	<updated>2023-03-13T00:00:00Z</updated>
	<id>https://mlcommons-science.netlify.app/</id>
	<author>
		<name>MLCommons</name>
		<email>laszewski@gmail.com</email>
	</author>
	
	<entry>
		<title>Cloudmask Improvements for Parallel Executions</title>
		<link href="https://mlcommons-science.netlify.app/blog/cloudmask-1/"/>
		<updated>2023-03-13T00:00:00Z</updated>
		<id>https://mlcommons-science.netlify.app/blog/cloudmask-1/</id>
		<content type="html">&lt;p&gt;The original cloudmask code contains a feature to save the training
model into a file that is later used for inference. However, at the
current time, the configuration file and the associated code save this
configuration file in a single location. If run in parallel the model
would be overwritten among parallel runs. To allow parallel execution
of cloudmask a mechanism to run the code on a permutation of different
parameters is used. For this we can reuse &lt;code&gt;cloudmesh-sbatch&lt;/code&gt; which
allows the creation of a number of subdirectories that contain a
modified &lt;code&gt;config.yaml&lt;/code&gt; file, as well as a custom-created batch
script. We also have modified the original python code to take into
consideration the new parameters in the YAML file.  This framework can
be adapted to various applications and HPC computers on which we
execute cloudmask.&lt;/p&gt;
&lt;p&gt;For more information, please contact Gregor von Laszewski
&lt;a href=&quot;mailto:laszewski@gmail.com&quot;&gt;laszewski@gmail.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code for cloudmesh-sbatch is available on
&lt;a href=&quot;https://pypi.org/project/cloudmesh-sbatch/&quot;&gt;GitHub and PyPi&lt;/a&gt;.&lt;/p&gt;
</content>
	</entry>
	
	<entry>
		<title>Revised Goal Statement</title>
		<link href="https://mlcommons-science.netlify.app/blog/goal-1/"/>
		<updated>2023-03-12T00:00:00Z</updated>
		<id>https://mlcommons-science.netlify.app/blog/goal-1/</id>
		<content type="html">&lt;p&gt;The goal of the MLCommons Research Science working group is to produce
artifacts that help advance science. These artifacts are structured as
benchmarks with datasets, reference model(s), and goals that cover
Science Research and Education. The primary goal is that our
benchmarks inspire research that achieves better scientific discovery
accuracy .through our benchmarks. However, training students by using
our artifacts in classes is also important. In this case, you can
submit either a report on the class or class notes that use our
artifacts to train the new scientists who will advance
discovery. Unlike other MLCommons groups, we do not have a closed
division but just the Research and Education open division that can
accept multiple types of submissions. We will index all submissions
and group them together into types of submissions. We only maintain a
leaderboard for scientific accuracy submissions. Note in some
inference examples, system performance needs to be improved to advance
science directly. Examples here include deep learning models for
microstructure in fluid calculations that must be invoked at every
grid point. Another example is online data analysis to select
interesting events in real time. Our GitHub is used to submit
artifacts for each submission, as in MLPerf training and
inference. But we also offer a wiki-like interface for you to describe
your submissions. Sometimes you may only need the latter if, for
example, you are describing a class use of our benchmark artifacts
without modification. The working group insists that all submissions
are properly described with metadata so we can help advance this
accessibility agenda.&lt;/p&gt;
</content>
	</entry>
</feed>
